{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f5fa47-d0d9-4d28-9071-cd0ad70e3159",
   "metadata": {},
   "source": [
    "# Predicting Algerian Forest Fires with Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1900e6b-f36b-480e-a0b3-24e0fd1b00ff",
   "metadata": {},
   "source": [
    "Authors: Ingrid Chien, Johnson Du, Minori Jaggia, Leif Martin Saether Sunde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02efc1a8-a7e6-4bf6-9763-66293c28bbd9",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Starting in June 2012, the Bejaia and Sidi-Bel Abbes regions of Algeria experienced numerous wildfires that likely resulted from a heat wave. The fires burned throuh Algeria's pine and cork oak forests, damaging a total area of 295 square kilometers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf5c181-e661-4aaf-a907-9fc6272f12c6",
   "metadata": {},
   "source": [
    "### Purpose of Analysis\n",
    "\n",
    "Do weather metrics in the Algerian regions determine the occureces of forest fires? How distinct are weather metrics for forest fires? How can we detect fires before they occur?\n",
    "\n",
    "Our team uses machine learning to process features and predict whether or not a fire will occur based on significant attributes. Our model is based on data from Bejaia and Sidi-Bel Abbes, but we aim to build more robust and generalizable models that can help policy makers in different regions implement precautionary measures against fires before they strike. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba532d-6d0a-4c40-922a-d614e2deefcf",
   "metadata": {},
   "source": [
    "### Assumptions\n",
    "\n",
    "In our analysis, we assume that the response variable is binary. The response variable is the class 'fire' or 'not fire.' We do not consider midway situations, such as fires that were close to ignition but utimately faded. We assume that our observations are unique instances with no extreme outliers. We also deduce that the samples are representative and large enough to make justifiable predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09123fb-6efa-4a84-b78c-52a8845eab6c",
   "metadata": {},
   "source": [
    "# The Data \n",
    "\n",
    "### Data Acquisition\n",
    "\n",
    "The multivariate dataset is acquired from the UCI Machine Learning repository. It can be found at https://archive.ics.uci.edu/ml/datasets/Algerian+Forest+Fires+Dataset++.\n",
    "\n",
    "The data contain a total of 244 instances for the two regions with 122 instances per region. There are 12 attributes, including date variables and weather metrics, that are measured from June 2012 to September 2012. Descriptions of the attributes can be found at the provided link. There are no missing values.\n",
    "\n",
    "There are 2 repsonse classes, 'fire' and 'not fire.'\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "The data is originally formatted as two stacked datasets where the top corresponds to Bejaia and the bottom correponds to Sidi-Bel Abbes. We combine them into one dataframe and create a 'Region' variable to distinguish regions. We reset the index and polish the column names for easy manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a72cf-f514-4eb1-92e9-d5bba891ac32",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c53a4fe-22fb-4bbd-a416-2089c8f0e93c",
   "metadata": {},
   "source": [
    "We first examine the correlation between all pairs of attributes except 'date' and 'time'. We find that some variables are highly correlated with one another, such as BUI and DC. These findings are later reflected in our feature selection process in modeling to avoid multicollinearity. \n",
    "\n",
    "### Pairwise Correlations\n",
    "![](figures/pairplot_all_quant.png)\n",
    "\n",
    "Let us focus on the relationships for fire behavior indicies and fuel moisture codes. We expect to see correlations. For example, one fuel moisture code should heavily effect another fuel moisture code, as they capture similar information.\n",
    "\n",
    "### Fire Behavior Indices\n",
    "![](figures/firebehaviour_indices.png)\n",
    "\n",
    "As expected, the variables rougly follow linear relationships and show positive correlation. It is no surprise that, for example, higher FWI induces higher BUI if larger fires are likely to have large buildups.\n",
    "\n",
    "### Fuel Moisture Codes\n",
    "![](figures/fuel_moisture_codes.png)\n",
    "\n",
    "DMC and DC roughly follow a linear relationship. The remaining relationships seems to be logarithmic, though the curves are quite sharp. As FFMC increases, DC stays consistent until around 80 FFMC where the spread increasees greatly. The FFMC is an inverse measure of moisture content for easily ignited surface litter and other cured fine fuels. Thus, it makes sense that FFMC increases as DC increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8ad49c-185b-4045-9837-ee5324aed0f1",
   "metadata": {},
   "source": [
    "Another interesting attribute is FWI. The distributions of FWI for 'fire' instances and 'not fire' instances drastically differ. If FWI is over about 8, then the data indicates we can be reasonably sure the instance is a 'fire'.\n",
    "\n",
    "### FWI Distributions\n",
    "<img src=\"figures/FWI_by_fire.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "Additional EDA shows that about half of the fires occured in July 2012. Also, there exists outliers in the 'Rain' attribute, but they are kept in the data because we assume consecutive days of heavy rain are natural.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad57eb0-dda3-4886-a035-9d1f44f18b6f",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "We build a random forest model and a logistic regression model to predict the occurence of forest fires.\n",
    "\n",
    "### Random Forest Model\n",
    "\n",
    "Our grid search cross validation searches the model and performs 10-fold cross validation on combinations of hyperparameters. We choose to  evaluate the model with recall because we prioritize penalzing false negatives. We want to avoid predicting no fire when there is actually a fire. \n",
    "\n",
    "From the figure below, we conclude that recall is stable when we use more than 35 trees and that results are best when the trees are depth 1. The cross validation results shows that the best hyperparameter choices are 38 trees with maximum depths of 1.\n",
    "\n",
    "<img src=\"figures/random_forest.png\" width=\"800\" height=\"800\">\n",
    "\n",
    "Our random forest model has great performance. The accuracy is 100%! Can we do better or worse with simple logistic regression?\n",
    "\n",
    "<img src=\"figures/random_forest_confusion.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "**Accuracy: 1.0**\n",
    "\n",
    "**Precision: 1.0**\n",
    "\n",
    "**Recall: 1.0**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac29bf-8916-41f5-bca8-ceed4050bfaa",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ba66ba-abfc-4773-b3d5-cbe57ac40b1f",
   "metadata": {},
   "source": [
    "By using logistic regression, we assume there is a possibility that the data can be linearly separated. Depending on which model does better, we make further assumptions about the nature of our data. If the random forest is superior, we believe the data is better suited for non linear algorithms. \n",
    "\n",
    "With previous EDA, we find that that DMC, DC, and BUI and highly correlated with one another. Only DMC is kept to avoid  multicollinearity. Notice how this step is skipped in the random forest model because the forest implicity performs feature subset selection. \n",
    "\n",
    "We use logistic regression with l2 regularization and the 'lbfgs' solver. Our logistic regression model also has great performance, though there are a few more errors compared to the random forest model. \n",
    "\n",
    "<img src=\"figures/logistic_regression_confusion.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "**Accuracy: 0.9629629629629629**\n",
    "\n",
    "**Precision: 0.9583333333333334**\n",
    "\n",
    "**Recall: 0.9787234042553191**\n",
    "\n",
    "To better undestand the model, let us examine the area under the ROC curve, which plots true positive rates against false positive rates for different thresholds.\n",
    "\n",
    "Amazingly, the area under the curve is close to 1! Our linear classifier is almost perfect, which leads us to believe the data can be linearly separated. \n",
    "\n",
    "<img src=\"figures/logistic_regression_roc.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac2281-8424-40ee-8f2c-5823cc673228",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Interpreting Results and Model Comparison\n",
    "\n",
    "Both models are extremely well-conditioned for the task of classifying forest fires. Even a simple logistic regression model with typical feature engineering achives a near perfect accuracy. Is it posisble that the data is inherently good for classification? Perhaps Algerian forest firest have particularly distinct features that make them easy to distinguish from regular forest conditions. From EDA, we see that most fires occured in July, leading us to believe that 'month' is a significant factor in determining fire occurence. \n",
    "\n",
    "The random forest outperforms the logistic model. This is expected because random forests are more expressive. The removal of correlated variables in the logistic model need not be the reason for poorer performance because they are calculated from kept features. The random forest succeeds by using a non linear split that cannot be represented by the logistic model.\n",
    "\n",
    "\n",
    "Our models are conditioned to predict fires in regions of Algeria. It is unclear how the models will respond to forest fires in other locations. We aim to conduct further exploration by training our models with data from different locations with similar climates. We can monitor the models' variances and ask the question: Are Algerian forest fires easier to predict than other forest fires?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67611423-009a-4284-a492-5abe938f488c",
   "metadata": {},
   "source": [
    "# Author Contributions\n",
    "\n",
    "\n",
    "**Johnson Du**\n",
    "\n",
    "- Responsible for `data_cleaning.ipynb`.\n",
    "- Responsible for the random forest classifier model (`random_forest.ipynb`, etc.)\n",
    "- Responsible for `restructure_data()` and `evaluate_model()` function in `tools\\utils.py`.\n",
    "- Responsible for writing tests for the util functions.\n",
    "- Responsible for `Makefile`.\n",
    "\n",
    "**Ingrid Chien**\n",
    "\n",
    "- Responsible for the logistic regresion model (`random_forest.ipynb`, etc.).\n",
    "- Responsible for the `normalize()` and `preprocess_data()` functions in `tools\\utils.py`.\n",
    "- Responsible for configuring `tools` as an installable package (`pyproj.toml`, `setup.py`, `setup.config`).\n",
    "- Responsible for writing report in `main.ipynb`.\n",
    "\n",
    "\n",
    "**Minori Jaggia**\n",
    "- Responsible for parts of `EDA.ipynb`\n",
    "- Responsible for `environment.yml`\n",
    "- Responsible for creating jupyterbook, binder link, and configuring github actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3acca-070c-4e1c-82ef-1995b616be02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
